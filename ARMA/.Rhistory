"nu", "Rsq", "ar1", "ar2" )
statisticsb
true.par          <- unlist(setups[i, ])
nu                <- nucalc(true.par[1], true.par[2], true.par[3], ar)
i in 1:nrow(setups)
i=1
true.par          <- unlist(setups[i, ])
nu                <- nucalc(true.par[1], true.par[2], true.par[3], ar)
load(paste("./MC/MC_3/Sim_R1000_n", true.par[1], "_d", true.par[2], "_r", true.par[3],
"_corr0.RData", sep=""))
results.list[[i]] <- RESULTS
MSE_d <- rowMeans((results.list[[i]][c("d", "d_45", "d_50", "d_55", "d_60", "d_65", "d_70"), ] - true.par$d)^2) %>%
sqrt(.)
MSE_d
load(paste("./MC/MC_3/Sim_R1000_n", true.par[1], "_d", true.par[2], "_r", true.par[3],
"_corr0.RData", sep=""))
results.list[[i]] <- RESULTS
RESULTS
results.list[[i]][c("d", "d_45", "d_50", "d_55", "d_60", "d_65", "d_70"), ]
MSE_d <- rowMeans((results.list[[i]][c("d", "d_45", "d_50", "d_55", "d_60", "d_65", "d_70"), ] - true.par[1])^2) %>%
sqrt(.)
MSE_d
MSE_d <- rowMeans((results.list[[i]][c("d", "d_45", "d_50", "d_55", "d_60", "d_65", "d_70"), ] - true.par[2])^2) %>%
sqrt(.)
MSE_d
MSE_ar <- rowMeans((results.list[[i]][c("ar_1", "ar_2"), ] - c(-1.6, 0.8))^2)%>%
sqrt(.)
#SSR   <- mean(results.list[[i]][c("SSR"), ])
Rsq   <- mean(results.list[[i]][c("Rsq"), ])
nu
MSE_nu <- mean((results.list[[i]][c("nu"), , drop=F] - unlist(nu))^2) %>%
sqrt(.)
MSE_nu
statistics[i, ] <- c(MSE_d, MSE_nu, Rsq, MSE_ar)
MSE_d <- apply((results.list[[i]][c("d", "d_45", "d_50", "d_55", "d_60", "d_65", "d_70"), ] - true.par[2]), 1, mean)
MSE_ar <- -apply((results.list[[i]][c("ar_1", "ar_2"), ] - c(-1.6, 0.8)), 1, mean)
MSE_nu <- mean((results.list[[i]][c("nu"), ] - unlist(nu)) )
statisticsb[i, ] <- c(MSE_d, MSE_nu, Rsq, MSE_ar)
statisticsb
for(i in 1:nrow(setups)){
true.par          <- unlist(setups[i, ])
nu                <- nucalc(true.par[1], true.par[2], true.par[3], ar)
try({
load(paste("./MC/MC_3/Sim_R1000_n", true.par[1], "_d", true.par[2], "_r", true.par[3],
"_corr0.RData", sep=""))
results.list[[i]] <- RESULTS
MSE_d <- rowMeans((results.list[[i]][c("d", "d_45", "d_50", "d_55", "d_60", "d_65", "d_70"), ] - true.par[2])^2) %>%
sqrt(.)
MSE_ar <- rowMeans((results.list[[i]][c("ar_1", "ar_2"), ] - c(-1.6, 0.8))^2)%>%
sqrt(.)
#SSR   <- mean(results.list[[i]][c("SSR"), ])
Rsq   <- mean(results.list[[i]][c("Rsq"), ])
MSE_nu <- mean((results.list[[i]][c("nu"), , drop=F] - unlist(nu))^2) %>%
sqrt(.)
statistics[i, ] <- c(MSE_d, MSE_nu, Rsq, MSE_ar)
MSE_d <- apply((results.list[[i]][c("d", "d_45", "d_50", "d_55", "d_60", "d_65", "d_70"), ] - true.par[2]), 1, mean)
MSE_ar <- -apply((results.list[[i]][c("ar_1", "ar_2"), ] - c(-1.6, 0.8)), 1, mean)
MSE_nu <- mean((results.list[[i]][c("nu"), ] - unlist(nu)) )
statisticsb[i, ] <- c(MSE_d, MSE_nu, Rsq, MSE_ar)
})
}
rownames(statistics) <- rownames(statisticsb) <- apply(setups[,], 1, function(x) paste(x, collapse="_"))
colnames(statistics) <- colnames(statisticsb) <- c("d",
"d_45", "d_50", "d_55", "d_60", "d_65", "d_70",
"nu", "Rsq", "ar1", "ar2" )
statistics
statisticsb
statistics
p <- length(ar)
A <- toComp(-ar)$CompMat
matrix(solve(diag(p^2)-(A%x%A))%*%c(1,rep(0,p^2-1)),p,p)
(1-ar[1]-ar[2])
(1-ar[1]^2-ar[2]^2)
(A%x%A)
diag(p^2)-(A%x%A)
solve(diag(p^2)-(A%x%A))
diag(p^2)-(A%x%A)
ARMAtoMA(ar = -ar)
ARMAtoMA(ar = -ar, lag.max=10)
ARMAtoMA(ar = -ar, lag.max=100)
ARMAtoMA(ar = -ar, lag.max=100)^2
ARMAtoMA(ar = -ar, lag.max=100)^2 %>% sum
solve(diag(p^2)-(A%x%A))%*%c(1,rep(0,p^2-1)),p,p)
matrix(solve(diag(p^2)-(A%x%A))%*%c(1,rep(0,p^2-1)),p,p)[
]
gc()
rm(list = ls())
library(fUCpack)
library(dplyr)
# Wd, etc
setwd("/Users/tobias/Dokumente/Projekte/filtering unknown persistence/R/")
source("./help functions/KF.R")
# Settings
n <- c(100, 200, 300)
d <- c(0.75, 1, 1.75)
r <- c(0, 1, 10, 30)
R <- 1000
ar = c(-1.6, 0.8)
setups <- expand.grid(n, d, r)
colnames(setups) <- c("n", "d", "r")
setups <- setups[order(setups[, "n"]), ]
# Long-run variance part
cvar <- function(ar){
p <- length(ar)
A <- toComp(-ar)$CompMat
return(matrix(solve(diag(p^2)-(A%x%A))%*%c(1,rep(0,p^2-1)),p,p)[1,1])
}
xvar <- function(n, d){
pisq <- frac_diff(c(1, rep(0, n-1)), -d)^2
var  <- cumsum(pisq)
return(mean(var))
}
# calculate the true nu:
nucalc <- function(n, d, ratio, ar){
if(ratio == 0) return(1)
var_x <- xvar(n, d)
var_c <- cvar(ar)
nu    <- var_x/var_c * (1 / ratio)
return(nu)
}
# Load CSS esimates
results.list <- list()
statistics <- statisticsb <- matrix(NA, nrow(setups), 11)
for(i in 1:nrow(setups)){
true.par          <- unlist(setups[i, ])
nu                <- nucalc(true.par[1], true.par[2], true.par[3], ar)
try({
load(paste("./MC/MC_3/Sim_R1000_n", true.par[1], "_d", true.par[2], "_r", true.par[3],
"_corr0.RData", sep=""))
results.list[[i]] <- RESULTS
MSE_d <- rowMeans((results.list[[i]][c("d", "d_45", "d_50", "d_55", "d_60", "d_65", "d_70"), ] - true.par[2])^2) %>%
sqrt(.)
MSE_ar <- rowMeans((results.list[[i]][c("ar_1", "ar_2"), ] - c(-1.6, 0.8))^2)%>%
sqrt(.)
#SSR   <- mean(results.list[[i]][c("SSR"), ])
Rsq   <- mean(results.list[[i]][c("Rsq"), ])
MSE_nu <- mean((results.list[[i]][c("nu"), , drop=F] - unlist(nu))^2) %>%
sqrt(.)
statistics[i, ] <- c(MSE_d, MSE_nu, Rsq, MSE_ar)
MSE_d <- apply((results.list[[i]][c("d", "d_45", "d_50", "d_55", "d_60", "d_65", "d_70"), ] - true.par[2]), 1, mean)
MSE_ar <- -apply((results.list[[i]][c("ar_1", "ar_2"), ] - c(-1.6, 0.8)), 1, mean)
MSE_nu <- mean((results.list[[i]][c("nu"), ] - unlist(nu)) )
statisticsb[i, ] <- c(MSE_d, MSE_nu, Rsq, MSE_ar)
})
}
rownames(statistics) <- rownames(statisticsb) <- apply(setups[,], 1, function(x) paste(x, collapse="_"))
colnames(statistics) <- colnames(statisticsb) <- c("d",
"d_45", "d_50", "d_55", "d_60", "d_65", "d_70",
"nu", "Rsq", "ar1", "ar2" )
statistics
statistics
statistics
r <- c(0, 30, 10, 1)
R <- 1000
ar = c(-1.6, 0.8)
setups <- expand.grid(n, d, r)
colnames(setups) <- c("n", "d", "r")
setups <- setups[order(setups[, "n"]), ]
# Long-run variance part
cvar <- function(ar){
p <- length(ar)
A <- toComp(-ar)$CompMat
return(matrix(solve(diag(p^2)-(A%x%A))%*%c(1,rep(0,p^2-1)),p,p)[1,1])
}
xvar <- function(n, d){
pisq <- frac_diff(c(1, rep(0, n-1)), -d)^2
var  <- cumsum(pisq)
return(mean(var))
}
# calculate the true nu:
nucalc <- function(n, d, ratio, ar){
if(ratio == 0) return(1)
var_x <- xvar(n, d)
var_c <- cvar(ar)
nu    <- var_x/var_c * (1 / ratio)
return(nu)
}
# Load CSS esimates
results.list <- list()
statistics <- statisticsb <- matrix(NA, nrow(setups), 11)
for(i in 1:nrow(setups)){
true.par          <- unlist(setups[i, ])
nu                <- nucalc(true.par[1], true.par[2], true.par[3], ar)
try({
load(paste("./MC/MC_3/Sim_R1000_n", true.par[1], "_d", true.par[2], "_r", true.par[3],
"_corr0.RData", sep=""))
results.list[[i]] <- RESULTS
MSE_d <- rowMeans((results.list[[i]][c("d", "d_45", "d_50", "d_55", "d_60", "d_65", "d_70"), ] - true.par[2])^2) %>%
sqrt(.)
MSE_ar <- rowMeans((results.list[[i]][c("ar_1", "ar_2"), ] - c(-1.6, 0.8))^2)%>%
sqrt(.)
#SSR   <- mean(results.list[[i]][c("SSR"), ])
Rsq   <- mean(results.list[[i]][c("Rsq"), ])
MSE_nu <- mean((results.list[[i]][c("nu"), , drop=F] - unlist(nu))^2) %>%
sqrt(.)
statistics[i, ] <- c(MSE_d, MSE_nu, Rsq, MSE_ar)
MSE_d <- apply((results.list[[i]][c("d", "d_45", "d_50", "d_55", "d_60", "d_65", "d_70"), ] - true.par[2]), 1, mean)
MSE_ar <- -apply((results.list[[i]][c("ar_1", "ar_2"), ] - c(-1.6, 0.8)), 1, mean)
MSE_nu <- mean((results.list[[i]][c("nu"), ] - unlist(nu)) )
statisticsb[i, ] <- c(MSE_d, MSE_nu, Rsq, MSE_ar)
})
}
rownames(statistics) <- rownames(statisticsb) <- apply(setups[,], 1, function(x) paste(x, collapse="_"))
colnames(statistics) <- colnames(statisticsb) <- c("d",
"d_45", "d_50", "d_55", "d_60", "d_65", "d_70",
"nu", "Rsq", "ar1", "ar2" )
statistics
statistics
# Simulation:
# Performance of fUC for parameter estimation
#   - High and normal signal to noise ratios
#   - AR plus non-AR
#   - compare d with other nonparametric estimators
gc()
rm(list = ls())
library(fUCpack)
library(dplyr)
library(parallel)
# Wd, etc
setwd("~/Dokumente/Projekte/filtering unknown persistence/R")
#setwd("/Users/tobias/Dokumente/Projekte/filtering unknown persistence/R/")
#source("./help functions/help_functions.R")
source("./help functions/KF.R")
# Settings
n <- c(100, 200, 300)
d <- c(0.75, 1, 1.75)
ratio <- c(1, 10, 30, 0)
R <- 1000
# Strong persistence
ar <- c(-1.6, 0.8)
# Long-run variance part
cvar <- function(ar){
p <- length(ar)
A <- toComp(-ar)$CompMat
return(matrix(solve(diag(p^2)-(A%x%A))%*%c(1,rep(0,p^2-1)),p,p)[1,1])
}
xvar <- function(n, d){
pisq <- frac_diff(c(1, rep(0, n-1)), -d)^2
var  <- cumsum(pisq)
return(mean(var))
}
setups <- expand.grid(n, d, ratio)
colnames(setups) <- c("n", "d", "ratio")
setups <- setups[order(setups[, "n"]), ]
# calculate the true nu:
nucalc <- function(n, d, ratio, ar){
if(ratio == 0) return(1)
var_x <- xvar(n, d)
var_c <- cvar(ar)
nu    <- var_x/var_c * (1 / ratio)
return(nu)
}
# get nu
nuc <- sapply(1:nrow(setups), function(x) nucalc(setups[x, 1], setups[x, 2], setups[x, 3], ar))
i=1
setup <- setups[ i, ]
n <- as.numeric(setup[1])
d <- as.numeric(setup[2])
nu <- nucalc(n, d, setups[i, 3], ar)
r <- setups[i, 3]
cat("Iteration ", i, "\n")
#if(file.exists(file = paste("./MC/MC_2/Sim_R", R, "_n", n, "_d", d, "_nu", nu, "_ar_high.RData", sep=""))) next
set.seed(42)
nu
# Generate the data
x <- frac_diff_multi(matrix(rnorm(n*R, mean=0, sd=1), n, R), -d)
u <- matrix(rnorm(n*R, mean=0, sd=sqrt(nu)), n, R)
c <- apply(u, 2, function(x) stats::filter(c(rep(0, length(ar)), x), filter = c(-ar), method = "recursive", sides = 1)[-(1:length(ar))])
y <- yy<-x + c
# grid of starting values
d.grid <- seq(0.75, 1.75, 0.25)
nu_grid <- c(0.01, 1, 100, 1000) %>% log()
ar.1.grid <- c(-1.8,  -1.6, -1.4)
ar2.grid  <- c(0.6,  0.8,  1)
gr.start <- expand.grid(d.grid, nu_grid, ar.1.grid, ar2.grid) %>% as.matrix()
gr.start <- gr.start[sapply(1:nrow(gr.start), function(i) toComp(-c(gr.start[i, 3:4]))$stable) ,]
optfn <- function(n, y, x){
tryCatch({
# Estimate
# check grid
grid.st <- cbind(gr.start, sapply(1:nrow(gr.start), function(i) fUC_opt(gr.start[i, ],
y=y, START = 1,
nulim = c(1/100, 1e+06),
deterministics = FALSE)))
par0 <- grid.st[which.min(grid.st[,5]),-5]
(est <- optim(par=par0, control = list(),
fn = fUC_opt, quiet = TRUE, START = 1,
y=y, method = "BFGS", nulim = c(1/100, 1e+06), d.int = c(0.5, 2.5),
deterministics = FALSE))
# check for corner solutions: d->0, d->2, nu->1/100, nu->1000000
j=1
while(est$par[1] < .05 | est$par[1] > 1.95 | exp(est$par[2]) < .05 | exp(est$par[2]) > 250000){
if(j > 10) break
j=j+1
par0 <- grid.st[order(grid.st[,5]),-5][j , ]
(est <- optim(par=par0,
fn = fUC_opt, quiet = TRUE, d.int = c(0.5, 2.5),
y=y, method = "BFGS", nulim = c(1/100, 1e+06),
deterministics = FALSE, START = 1))
}
par <- est$par
nu  <- exp(par[2])
ar <- est$par[-(1:2)]
#KF <- fUC_comp(y, par[1], nu, ar)
#KF2 <- fUC_comp((1:length(y))^par[1], par[1], nu, ar)
#mu  <- summary(lm(KF$v ~ -1 + KF2$v))$coefficients[1,1]
KS <- fUC_smooth(y, par[1], nu, ar = ar, corr = FALSE)
Rsq <- summary(lm(x ~ KS$x))$r.squared
# Return results
results <- c(par[1], exp(par[2]), ar, Rsq)
names(results) <- c("d", "nu", "ar_1", "ar_2", "Rsq")
return(results)
}, error = function(e) return(rep(NA, 5))
)
}
optfn(n, y[,1], x[,1])
### fUC part
cl <- makeCluster(7)
clusterExport(cl, c("optfn", "fUC_opt", "y", "fUC_comp", "ma_inf",
"embed0", "fUC_smooth", "x", "frac_diff", "lm", "n", "gr.start"))
clusterEvalQ(cl, library(fUCpack))
RESULTS <- parSapply(cl, 1:R, function(j) optfn(n, y[, j], x[, j]))
stopCluster(cl)
RESULTS
rowMeans(RESULTS)
nu
nu
u
plot(u[,1])
y=y[,1]
y
# Estimate
# check grid
grid.st <- cbind(gr.start, sapply(1:nrow(gr.start), function(i) fUC_opt(gr.start[i, ],
y=y, START = 1,
nulim = c(1/100, 1e+06),
deterministics = FALSE)))
grid.st
par0 <- grid.st[which.min(grid.st[,5]),-5]
par0
(est <- optim(par=par0, control = list(),
fn = fUC_opt, quiet = TRUE, START = 1,
y=y, method = "BFGS", nulim = c(1/100, 1e+06), d.int = c(0.5, 2.5),
deterministics = FALSE))
est
# check for corner solutions: d->0, d->2, nu->1/100, nu->1000000
j=1
while(est$par[1] < .05 | est$par[1] > 1.95 | exp(est$par[2]) < .05 | exp(est$par[2]) > 250000){
if(j > 10) break
j=j+1
par0 <- grid.st[order(grid.st[,5]),-5][j , ]
(est <- optim(par=par0,
fn = fUC_opt, quiet = TRUE, d.int = c(0.5, 2.5),
y=y, method = "BFGS", nulim = c(1/100, 1e+06),
deterministics = FALSE, START = 1))
}
par <- est$par
nu  <- exp(par[2])
nu
ar <- est$par[-(1:2)]
ar
KS <- fUC_smooth(y, par[1], nu, ar = ar, corr = FALSE)
Rsq <- summary(lm(x ~ KS$x))$r.squared
plot(RESULTS[2,])
hist(RESULTS[2,])
j=33
setup <- setups[ i, ]
setup
setups
n=300
d=1.75
r=1
setups[i, 3]=1
nu <- nucalc(n, d, setups[i, 3], ar)
r <- setups[i, 3]
r
nu
i=1
setup <- setups[ i, ]
n <- as.numeric(setup[1])
d <- as.numeric(setup[2])
nu <- nucalc(n, d, setups[i, 3], ar)
r <- setups[i, 3]
cat("Iteration ", i, "\n")
#if(file.exists(file = paste("./MC/MC_2/Sim_R", R, "_n", n, "_d", d, "_nu", nu, "_ar_high.RData", sep=""))) next
set.seed(42)
# Generate the data
x <- frac_diff_multi(matrix(rnorm(n*R, mean=0, sd=1), n, R), -d)
u <- matrix(rnorm(n*R, mean=0, sd=sqrt(nu)), n, R)
c <- apply(u, 2, function(x) stats::filter(c(rep(0, length(ar)), x), filter = c(-ar), method = "recursive", sides = 1)[-(1:length(ar))])
y <- yy<-x + c
# grid of starting values
d.grid <- seq(0.75, 1.75, 0.25)
nu_grid <- c(0.01, 1, 100, 1000) %>% log()
ar.1.grid <- c(-1.8,  -1.6, -1.4)
ar2.grid  <- c(0.6,  0.8,  1)
gr.start <- expand.grid(d.grid, nu_grid, ar.1.grid, ar2.grid) %>% as.matrix()
gr.start <- gr.start[sapply(1:nrow(gr.start), function(i) toComp(-c(gr.start[i, 3:4]))$stable) ,]
optfn <- function(n, y, x){
tryCatch({
# Estimate
# check grid
grid.st <- cbind(gr.start, sapply(1:nrow(gr.start), function(i) fUC_opt(gr.start[i, ],
y=y, START = 1,
nulim = c(1/100, 1e+06),
deterministics = FALSE)))
par0 <- grid.st[which.min(grid.st[,5]),-5]
(est <- optim(par=par0, control = list(),
fn = fUC_opt, quiet = TRUE, START = 1,
y=y, method = "BFGS", nulim = c(1/100, 1e+06), d.int = c(0.5, 2.5),
deterministics = FALSE))
# check for corner solutions: d->0, d->2, nu->1/100, nu->1000000
j=1
while(est$par[1] < .05 | est$par[1] > 1.95 | exp(est$par[2]) < .05 | exp(est$par[2]) > 25000){
if(j > 10) break
j=j+1
par0 <- grid.st[order(grid.st[,5]),-5][j , ]
(est <- optim(par=par0,
fn = fUC_opt, quiet = TRUE, d.int = c(0.5, 2.5),
y=y, method = "BFGS", nulim = c(1/100, 1e+06),
deterministics = FALSE, START = 1))
}
par <- est$par
nu  <- exp(par[2])
ar <- est$par[-(1:2)]
#KF <- fUC_comp(y, par[1], nu, ar)
#KF2 <- fUC_comp((1:length(y))^par[1], par[1], nu, ar)
#mu  <- summary(lm(KF$v ~ -1 + KF2$v))$coefficients[1,1]
KS <- fUC_smooth(y, par[1], nu, ar = ar, corr = FALSE)
Rsq <- summary(lm(x ~ KS$x))$r.squared
# Return results
results <- c(par[1], exp(par[2]), ar, Rsq)
names(results) <- c("d", "nu", "ar_1", "ar_2", "Rsq")
return(results)
}, error = function(e) return(rep(NA, 5))
)
}
#optfn(n, y[,1], x[,1])
### fUC part
cl <- makeCluster(7)
clusterExport(cl, c("optfn", "fUC_opt", "y", "fUC_comp", "ma_inf",
"embed0", "fUC_smooth", "x", "frac_diff", "lm", "n", "gr.start"))
clusterEvalQ(cl, library(fUCpack))
RESULTS <- parSapply(cl, 1:R, function(j) optfn(n, y[, j], x[, j]))
stopCluster(cl)
RESULTS[2,]
plot(RESULTS[2,])
rowMeans(RESULTS)
# Simulation:
# Performance of fUC for parameter estimation
#   - High and normal signal to noise ratios
#   - AR plus non-AR
#   - compare d with other nonparametric estimators
gc()
rm(list = ls())
library(fUCpack)
library(dplyr)
library(parallel)
library(CFFpack)
# Wd, etc
setwd("~/Dokumente/Projekte/filtering unknown persistence/R")
source("./help functions/fUC_arma_approx.R")
#setwd("/Users/tobias/Dokumente/Projekte/filtering unknown persistence/R/")
#source("./help functions/help_functions.R")
source("./help functions/KF.R")
# Settings
n <- c(100, 200, 300)
d <- c(0.75, 1, 1.75)
ratio <- c(1, 10, 30, 0)
R <- 1000
# Strong persistence
ar <- c(-1.6, 0.8)
# Long-run variance part
cvar <- function(ar){
p <- length(ar)
A <- toComp(-ar)$CompMat
return(matrix(solve(diag(p^2)-(A%x%A))%*%c(1,rep(0,p^2-1)),p,p)[1,1])
}
xvar <- function(n, d){
pisq <- frac_diff(c(1, rep(0, n-1)), -d)^2
var  <- cumsum(pisq)
return(mean(var))
}
setups <- expand.grid(n, d, ratio)
colnames(setups) <- c("n", "d", "ratio")
setups <- setups[order(setups[, "n"]), ]
# calculate the true nu:
nucalc <- function(n, d, ratio, ar){
if(ratio == 0) return(1)
var_x <- xvar(n, d)
var_c <- cvar(ar)
nu    <- var_x/var_c * (1 / ratio)
return(nu)
}
# get nu
nuc <- sapply(1:nrow(setups), function(x) nucalc(setups[x, 1], setups[x, 2], setups[x, 3], ar))
# define grid
data(list=paste("d2arma",3,3,"_n",2082,sep =""))
# define grid
data(list=paste("d2arma",3,3,"_n",100,sep =""))
# define grid
data(list=paste("d2arma",3,3,"_n",200,sep =""))
# define grid
data(list=paste("d2arma",3,3,"_n",300,sep =""))
library(CFFpack)
getwd()
CFFpack::ARMA_approx
setwd("/Users/tobias/Dokumente/Projekte/Filtering unknown persistence/R/code/ARMA")
CFFpack::ARMA_approx(p=3, q=3, n=100, ncl=4)
CFFpack::ARMA_approx(p=3, q=3, n=200, ncl=4)
CFFpack::ARMA_approx(p=3, q=3, n=300, ncl=4)
fUC_KS_ARMA_approx
